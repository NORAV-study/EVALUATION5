---
title: "CO2 atmosphérique Hawai"
author: "Nomena Ravelojaona"
date: "21/07/2020"
output: github_document
---
  
  
## Importation des données

  Les données du fichier hawai.csv comprennent les moyennes des mesures mensuelles de CO2 atmosphérique en ppm-volume collectées au *Mauna Loa Observatory* à Hawaii de mars 1958 à décembre 2001, inclusivement.

```{r}
library(tidyverse)
options(max.print=1000000)
hawai <- read.csv(file =  "hawai.csv", header = TRUE)
head(hawai,8 )
```


## création de la série temporelle
Une série temporelle du CO2 est créée à partir des données de hawai.csv


```{r}
library("forecast")
library("fpp2")
hawai_ts <- ts(hawai %>% dplyr::select(-time),
               start = c(hawai$time[1], 1),
               frequency = 12)
head(hawai_ts, 24)
autoplot(hawai_ts)
```


On observe sur la figure la tendance globale de la quantité de CO2. Probablement, cette tendance à la hausse est expliquée par l'augmentation des activités humaines mobilisant des énergies fossiles qui permettent de libérer une quantité significative de CO2.

## Séparation la série en partie d'entraînement (environ 70% des données) et en partie *test*

Pour créer un modèle permettant de prédire la quantité de CO2 atmosphérique mesurée à Mauna Loa Observatory* à Hawai, nous allons répartir nos données en 2 blocs : le premier bloc servira de données d'*entrainement* pour générer le modèle et le deuxième bloc sera utilisé comme données *test*.

```{r}
hawai_train <- head(hawai_ts, round(length(hawai_ts) * 0.7)) ## le premier bloc qui constitue les données d'entrainement (70%)
head(hawai_train, 24)
h <- length(hawai_ts) - length(hawai_train)
hawai_test <- tail(hawai_ts, h) ## les 30% restant qui comprennent les données tests
head(hawai_test, 24)

autoplot(hawai_train) + autolayer(hawai_test)
```


Les données d'entrainement comprenant les 70% contiennent la serie temporelle de mars 1958 à octobre 1988. Les données *test* vont de novembre 1988 à décembre 2001. 

## Création du modèle prévisionnel

Avant de créer le modèle, nous allons analyser notre série temporelle.

**AUTOCORRELATION**

```{r}
library("cowplot")
plot_grid(ggAcf(hawai_train) + ggtitle("hawai: Autocorrélation"))
```

La visualisation des seuils de signification de l’autocorrélation indique que nous pouvons effectuer une modélisation prédictive avec la série temporelle. Une corrélation positive significative existe pour nos données.


**Calcul de la probabilité pour voir si nos données constituent ou non un bruit blanc**

```{r}
Box.test(hawai_train, lag = 20, type = "Ljung-Box") ## Pour tester si si la série temporelle entière peut être différenciée d’un bruit blanc.
```

Le *p-value* très faible indique que la probabilité que la série soit un bruit blanc est presque nulle.

**Modélisation de la série temporelle**

Le modèle ETS(*error, tend and seasonnal*) a été retenu pour modéliser notre série temporelle.
Il s'agit d'un modèle qui automatise la prévision. A l'issu de l'optimisation du choix de modèle, un modèle parmi les types de modèles de la famille SES sera retenu.


```{r}
hawai_model <- forecast::ets(hawai_train, model = "ZZZ") ## pour générer le modèle
hawai_model
autoplot(hawai_model)
hawai_forecast <- forecast(hawai_model,h= 12*13 ) ## pour obtenir la prédiction
autoplot(hawai_forecast)

accuracy(hawai_model)
```

Le modèle retenu est un ETS(A,A,A), définissant dans l’ordre le type d’erreur, de tendance et de saison Nous avons une erreur, une tendance  et une saison de type A (additive). 


## Comparaison avec les données test

Le modèle généré sera évalué avec les données *test* de la série temporelle

```{r}
autoplot(hawai_forecast)+ autolayer(hawai_test)
```

Le modèle parvient a bien prédire les occurrences futures. La courbe générée par le modèle parvient à suivre la trace de la courbe des données observées avec quand même un petit décalage.
L’intervalle de confiance à 95% de la prévision de long terme croît à un niveau d’incertitude peu utile
dans la pratique.

```{r}
test_set_accuracy <- hawai_model %>% forecast(h = 12*13) %>%
  accuracy(hawai_test) ## test set
test_set_accuracy[,c("ME","RMSE","MAE","MAPE","MASE")]
```


Les indicateurs des écarts nous montrent que les érreurs du modèle ont faiblement augmenté avec les données *test* comparativement aux données d'*entrainement*, une situation qui n'est pas  du tout inhabituelle. Un bon ajustement aux données d'entraînement n'indique pas forcément que le modèle fera de bonnes prévisions.Et c'est bien l'intérêt de procéder à l'utilisation d'une partie de données comme données *test*.
Dans la prévision, les erreurs sont vraisemblablement accentuées à fur et à mesure que l'on avance dans le temps.


## Analyse des résidus


```{r}
checkresiduals(hawai_model)
```


La p-value étant très faible, il est peu probable que les résidus forment un bruit blanc. Les résidus contiennent de l’autocorrélation, ce qui veut dire qu'il existe une structure dans les résidus. Le modèle ne réussit totalement pas à capturer toute la dynamique des données. Néanmoins, l’estimation ponctuelle reste non biaisée.

A ce stade le modèle est fiable pour prédire la quantité de CO2 atmosphérique mesurée dans la station sur un moyen terme. En effet, l'indice de confiance qui croit à long terme nous suggère que il est plus adéquat de se concentrer sur la prévision n'allant pas sur une durée trop longue genre plus de 10-15ans pour avoir une prévision acceptable. Dans cet intervalle de temps, les prévisions sont encore moins incertaines car la taille de l’intervalle de confiance à 95% est encore plus faible.

Cependant, une amélioration de la prévision est toujours possible. Une piste évidente à poursuivre est d'adopter un modèle dynamique qui permet de prendre en compte des variables explicatives exogènes.Il pourait aussi être intéressant d’explorer des modèles à mémoire longue, de type ARFIMA (GRANGER et JOYEUX [1980] et HOSKING [1981]), pour capturer les très fortes inerties présentes dans les résidus.







```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


